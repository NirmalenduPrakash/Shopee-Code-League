{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "b4SR7hChbqqk",
    "outputId": "a82d2355-98ed-4425-dd07-25bc48dda410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading test_tcn.csv to /content\n",
      "  0% 0.00/607k [00:00<?, ?B/s]\n",
      "100% 607k/607k [00:00<00:00, 90.8MB/s]\n",
      "Downloading train_en.csv.zip to /content\n",
      " 47% 5.00M/10.7M [00:00<00:00, 17.9MB/s]\n",
      "100% 10.7M/10.7M [00:00<00:00, 26.9MB/s]\n",
      "Downloading train_tcn.csv.zip to /content\n",
      " 78% 17.0M/21.7M [00:00<00:00, 35.3MB/s]\n",
      "100% 21.7M/21.7M [00:00<00:00, 49.0MB/s]\n",
      "Downloading dev_en.csv to /content\n",
      "  0% 0.00/55.2k [00:00<?, ?B/s]\n",
      "100% 55.2k/55.2k [00:00<00:00, 55.4MB/s]\n",
      "Downloading dev_tcn.csv to /content\n",
      "  0% 0.00/60.8k [00:00<?, ?B/s]\n",
      "100% 60.8k/60.8k [00:00<00:00, 61.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c shopee-product-title-translation-open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox05q68Mb3Kc"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "for file in ['train_tcn.csv.zip','train_en.csv.zip']:\n",
    "  with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "      zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "RnsMAzs1b6oX",
    "outputId": "38b5dc83-aae4-4bde-8686-90ecf0c40280"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gucci Gucci Guilty Pour Femme Stud Edition 罪愛女...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>（二手）PS4 GTA 5 俠盜獵車手5 Grand Theif Auto V繁體 中文版</td>\n",
       "      <td>Game Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>百獸卡</td>\n",
       "      <td>Life &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nac nac活氧全效柔衣素</td>\n",
       "      <td>Mother &amp; Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Nike耐吉官方F.C. 男子足球長褲新款標準型 拒水 拉鏈褲腳\\nCD0557</td>\n",
       "      <td>Men's Apparel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>火影忍者六道鸣人cos睡衣卡卡西宇智波佐助T恤二次元动漫短袖衣服</td>\n",
       "      <td>Women's Apparel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>第二代新巴克史萊姆 210ml 限量版</td>\n",
       "      <td>Life &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aaL皮商旋.全新鐵鍋上五花肉造型立體冰箱貼/磁鐵!--值得收藏!/6房樂箱19/-P</td>\n",
       "      <td>Life &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>現貨24小時快速出貨chanel香奈兒58601女包經典菱格時尚單肩包側背包斜跨包ch</td>\n",
       "      <td>Women Bags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>【小拇指鞋坊】Adidas Superstar 80s DLX 金標 貝殼頭 白紅 時尚男女...</td>\n",
       "      <td>Women Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_title              category\n",
       "0  Gucci Gucci Guilty Pour Femme Stud Edition 罪愛女...       Health & Beauty\n",
       "1      （二手）PS4 GTA 5 俠盜獵車手5 Grand Theif Auto V繁體 中文版          Game Kingdom\n",
       "2                                                百獸卡  Life & Entertainment\n",
       "3                                     nac nac活氧全效柔衣素         Mother & Baby\n",
       "4          #Nike耐吉官方F.C. 男子足球長褲新款標準型 拒水 拉鏈褲腳\\nCD0557         Men's Apparel\n",
       "5                   火影忍者六道鸣人cos睡衣卡卡西宇智波佐助T恤二次元动漫短袖衣服       Women's Apparel\n",
       "6                                第二代新巴克史萊姆 210ml 限量版  Life & Entertainment\n",
       "7        aaL皮商旋.全新鐵鍋上五花肉造型立體冰箱貼/磁鐵!--值得收藏!/6房樂箱19/-P  Life & Entertainment\n",
       "8        現貨24小時快速出貨chanel香奈兒58601女包經典菱格時尚單肩包側背包斜跨包ch            Women Bags\n",
       "9  【小拇指鞋坊】Adidas Superstar 80s DLX 金標 貝殼頭 白紅 時尚男女...           Women Shoes"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_cn=pd.read_csv('train_tcn.csv')\n",
    "df_cn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "jUrSWrYVb89H",
    "outputId": "457f6555-7e46-43ef-8200-8d5bbb907fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWI5yxvZdUCN"
   },
   "source": [
    "# More chinese BERT config available-\n",
    "https://github.com/ymcui/Chinese-BERT-wwm/blob/master/README_EN.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860,
     "referenced_widgets": [
      "47644331ac4746169a1055aef96dde93",
      "3ab1015f09cc4d4580cd5a870b68a495",
      "0d432b2a8a444774a633b01b4ca9de4d",
      "f8854582c97a41bb827c7f251a9c14bc",
      "ed275708b57c4429ac285641ee9c2552",
      "854d272bf39743d1986ab2fad2eced50",
      "96a1db5631ea4637bfa97beeec4d9f84",
      "bee1edf2183d4849a7c70e95061808eb",
      "e1aca9d720cc47cb8bcc5399218d4ee6",
      "46f8f2e1fb1c4ceb80f683568410cf10",
      "84329afb19a54968b62641dfad534c43",
      "0474a13e1a2c454d997ea9c368f9f8cf",
      "92c828dbb21c41ccaacb9d2bfbb65406",
      "01bb59f213e2455cb6256bf178b3b3f2",
      "a31e3217a21d4ab0a641c2e97f49f795",
      "573c1b92dbfd4518826440c03290d70e",
      "5cc93970325e47419a7b82bcd7d0747c",
      "f6448e4550de464b850565bba205beed",
      "76076bd868784a2780e983fa241b955c",
      "36510477d3854a7faeb4a8b6290091f3",
      "d6ad9a578195430dacfff55635cf9aa5",
      "b9ed44d648794bb098c93cefa0fd226d",
      "6e73e180864c4d7aa69cc79ddbf46b9c",
      "2139e1f088fb498295fc8a8f5ed91504",
      "ec8bb762f2a14ad89514ab85327aacda",
      "79453e6b7af14f7a86fa9c1be554c884",
      "03084dc3b06f465ca353179a69aabab6",
      "f8ec86f5aaa3480f9edd0029a1640fc9",
      "f43d78c1b4e94062adb2959c19fe0899",
      "8aaeee085ebd45bfa6291b523c26d901",
      "4752f00e5ea34933b21643fb0504bcb8",
      "42ef4a3dc3144ca7a29ff9ce166232c1",
      "de8dcb8b37014090882fccf4f1084577",
      "c03f2b0ab812481f8770f4ea502fa2dd",
      "1d3c2a86a1254f4cadb895e9b41e388c",
      "bd0a9e1bff99445da474823b5035fae5",
      "e234cb4a063a4967b1cdd746fa4be3d9",
      "a7cb48430c834a90b30ec720737a0995",
      "36e3a5e0459a42c6ae56b904a3c5b8d3",
      "a779e50ab1244f5db3fefd623542a8e0"
     ]
    },
    "colab_type": "code",
    "id": "JCwF3mCZcPmM",
    "outputId": "66747975-6ba0-431b-e8c3-4b66d62920a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 27.6MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20kB 6.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 40kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 51kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 61kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 81kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 92kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 102kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 112kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 122kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 133kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 143kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 153kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 163kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 174kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 184kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 204kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 215kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 225kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 235kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 245kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 256kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 266kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 276kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 286kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 296kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 307kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 317kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 327kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 337kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 348kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 358kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 368kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 378kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 389kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 399kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 409kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 419kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 430kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 440kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 450kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 460kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 471kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 481kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 491kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 501kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 512kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 522kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 532kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 542kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 552kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 563kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 573kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 583kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 593kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 604kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 614kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 624kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 634kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 645kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 655kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 665kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 675kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 686kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 696kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 706kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 716kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 727kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 737kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 747kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 757kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 768kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 778kB 8.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 23.5MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 62.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 54.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b9247423206a023eb82166d871bfbb5455eefd367efb3290fdfc2917cca3c8b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47644331ac4746169a1055aef96dde93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1aca9d720cc47cb8bcc5399218d4ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc93970325e47419a7b82bcd7d0747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8bb762f2a14ad89514ab85327aacda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8dcb8b37014090882fccf4f1084577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=19.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "en_tokenizer=BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "# en_bert_layer=BertModel.from_pretrained('/content/drive/My Drive/BERT_CONFIG')\n",
    "cn_tokenizer=BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "# cn_bert_layer=BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\",is_decoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8R4QZPm0cXga"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parameter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raxnQid_dvWk"
   },
   "source": [
    "# Adding start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUDYfdOccZ2L"
   },
   "outputs": [],
   "source": [
    "en_tokenizer.vocab.update({'<s>':len(en_tokenizer),'</s>':len(en_tokenizer)+1})\n",
    "cn_tokenizer.vocab.update({'<s>':len(cn_tokenizer),'</s>':len(cn_tokenizer)+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyV0laFScbb8"
   },
   "outputs": [],
   "source": [
    "class Monolingual_CN_Dataset(Dataset):\n",
    "  def __init__(self,df):\n",
    "    self.df=df\n",
    "    self.cn_pad_id=cn_tokenizer.convert_tokens_to_ids('[PAD]')     \n",
    "\n",
    "  def __len__(self): \n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    tokens=cn_tokenizer.tokenize(str(self.df.iloc[index]['product_title']))\n",
    "    # tokens=analyzer.parse(self.df.iloc[index]['product_title']).tokens()\n",
    "    cn_encoding=[cn_tokenizer.convert_tokens_to_ids(token) for token in tokens]\n",
    "    return {'src':tokens,'x_len':len(tokens),'x':cn_encoding}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9IjDI7_d2uz"
   },
   "source": [
    "# Sequence length limited to 50, due to memory considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nu56xQlucdKs"
   },
   "outputs": [],
   "source": [
    "def pad(tokens,en=True):\n",
    "  en_pad_id=en_tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "  cn_pad_id=cn_tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "  if(len(tokens)<50):\n",
    "    if(en):\n",
    "      return tokens+[en_pad_id for _ in range(50-len(tokens))]\n",
    "    else:\n",
    "      return tokens+[cn_pad_id for _ in range(50-len(tokens))]      \n",
    "  else:\n",
    "    return tokens[:50]\n",
    "\n",
    "def my_collate(batch,en=True):\n",
    "    max_x=np.max([item['x_len'] for item in batch])\n",
    "    if(max_x>50):\n",
    "      max_x=50 \n",
    "    x = [pad(item['x'],en=False) for item in batch]\n",
    "    if(en):\n",
    "      attn_mask=[list(map(lambda tok: [1 if tok!=\\\n",
    "                    en_tokenizer.convert_tokens_to_ids('[PAD]') else 0],item)) for item in x ]    \n",
    "    else:\n",
    "      attn_mask=[list(map(lambda tok: [1 if tok!=\\\n",
    "                    cn_tokenizer.convert_tokens_to_ids('[PAD]') else 0],item)) for item in x ]       \n",
    "    src=[item['src'] for item in batch]\n",
    "    return {'x':x,'src':src,'attn_mask':attn_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqRA_eZpcfWv"
   },
   "outputs": [],
   "source": [
    "data=df_cn.sample(10000,axis=0)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train=data[msk]\n",
    "val=data[~msk]\n",
    "train_set=Monolingual_CN_Dataset(train)\n",
    "val_set=Monolingual_CN_Dataset(val)\n",
    "train_loader=DataLoader(train_set, batch_size = 20,collate_fn=my_collate)\n",
    "val_loader = DataLoader(val_set, batch_size = 20,collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hVxmy6AchZk"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzVTQlqgek-X"
   },
   "source": [
    "# I tried teacher forcing for faster training...could use beam search on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omAw4L3kcjEv"
   },
   "outputs": [],
   "source": [
    "class Translator_EN_CN(nn.Module):\n",
    "  def __init__(self):\n",
    "        super(Translator_EN_CN, self).__init__()\n",
    "        # self.enc_layer = BertModel.from_pretrained('bert-base-uncased',\\\n",
    "        #                                            output_hidden_states=True).half()\n",
    "        self.enc_layer=BERT_en_encoder\n",
    "        for p in self.enc_layer.parameters():\n",
    "            p.requires_grad = False        \n",
    "        # self.dec_layer = BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\"\\\n",
    "        #                             ,is_decoder=True,num_hidden_layers=1,num_attention_heads=1)\n",
    "        self.dec_layer = Decoder(768,len(cn_tokenizer))\n",
    "        self.dec_layer.load_my_state_dict(BERT_cn_encoder.state_dict())        \n",
    "        self.linear = nn.Linear(768, len(cn_tokenizer))        \n",
    "        self.copy = nn.Linear(768,768)\n",
    "        self.enc_layer.resize_token_embeddings(len(en_tokenizer))\n",
    "        # self.dec_layer.resize_token_embeddings(len(cn_tokenizer))\n",
    "  def load_my_state_dict(self, state_dict):\n",
    "      own_state = self.state_dict()\n",
    "      for name, param in state_dict.items():\n",
    "          if name not in own_state:\n",
    "                continue\n",
    "          if isinstance(param, torch.nn.Parameter):\n",
    "              # backwards compatibility for serialized parameters\n",
    "              param = param.data\n",
    "          own_state[name].copy_(param)        \n",
    "  def forward(self, en_encoding,en_attn_mask,target,length=50):      \n",
    "      enc_hidden,_,all_hidden_layer = self.enc_layer(en_encoding, attention_mask = en_attn_mask)\n",
    "      batch_size=enc_hidden.size(0)\n",
    "      # pred=torch.zeros((batch_size,512),device=device)\n",
    "      y=torch.tensor([cn_tokenizer.convert_tokens_to_ids('<s>')] * batch_size,dtype=torch.long,device=device).view(-1,1)\n",
    "      for _e in range(length):     \n",
    "        output=self.dec_layer(y,all_hidden_layer)\n",
    "        # print(output.shape)\n",
    "        # _,output=self.dec_layer(input_ids=y,encoder_hidden_states=enc_hidden,encoder_attention_mask=en_attn_mask)        \n",
    "        transformed=self.copy(output[:,-1:,:])\n",
    "        copy_scores=torch.bmm(enc_hidden,transformed.transpose(1,2))  \n",
    "        # copy_scores=torch.bmm(enc_hidden,transformed.unsqueeze(-1))  \n",
    "        gen_scores=self.linear(output[:,-1:,:])\n",
    "        # y=torch.tensor(pred[:,_e],dtype=torch.long,device=device).view(-1,1) \n",
    "        # own decoder       \n",
    "        y_pred=torch.tensor(torch.argmax(gen_scores,dim=-1),dtype=torch.long,device=device).view(-1,1) \n",
    "        # teacher forcing\n",
    "        y_teacher=target[:,_e].view(-1,1)    \n",
    "        y_pred=y_teacher*(y_teacher<len(cn_tokenizer))+\\\n",
    "            (y_teacher>len(cn_tokenizer))*y_pred\n",
    "        y=torch.cat((y,y_pred),dim=-1)\n",
    "        yield gen_scores,copy_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-95cP3WeeBOW"
   },
   "source": [
    "# Pre-trained BERT as decoder repeats tokens, so using my own decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pwojn2qrcm_Y"
   },
   "outputs": [],
   "source": [
    "class Translator_CN_EN(nn.Module):\n",
    "  def __init__(self):\n",
    "        super(Translator_CN_EN, self).__init__()\n",
    "        # self.enc_layer = BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\",\\\n",
    "        #                                            output_hidden_states=True).half()\n",
    "        self.enc_layer=BERT_cn_encoder\n",
    "        for p in self.enc_layer.parameters():\n",
    "            p.requires_grad = False                                \n",
    "        self.dec_layer = Decoder(768,len(en_tokenizer))\n",
    "        self.dec_layer.load_my_state_dict(BERT_en_encoder.state_dict())\n",
    "        self.linear = nn.Linear(768, len(en_tokenizer))        \n",
    "        self.copy = nn.Linear(768,768)\n",
    "        self.enc_layer.resize_token_embeddings(len(cn_tokenizer))\n",
    "        # self.dec_layer.resize_token_embeddings(len(en_tokenizer))\n",
    "  def load_my_state_dict(self, state_dict):\n",
    "      own_state = self.state_dict()\n",
    "      for name, param in state_dict.items():\n",
    "          if name not in own_state:\n",
    "                continue\n",
    "          if isinstance(param, torch.nn.Parameter):\n",
    "              # backwards compatibility for serialized parameters\n",
    "              param = param.data\n",
    "          own_state[name].copy_(param)\n",
    "  def forward(self, cn_encoding,cn_attn_mask,length=50):\n",
    "      enc_hidden,_,all_layer_hidden = self.enc_layer(cn_encoding, attention_mask = cn_attn_mask)      \n",
    "      batch_size=enc_hidden.size(0)\n",
    "      # pred=torch.zeros((batch_size,512),device=device)\n",
    "      y=torch.tensor([en_tokenizer.convert_tokens_to_ids('<s>')] * batch_size,dtype=torch.long,device=device).view(-1,1)\n",
    "      for _e in range(length):     \n",
    "        # print(self.dec_layer.embeddings) \n",
    "        output=self.dec_layer(y,all_layer_hidden)\n",
    "        # _,output=self.dec_layer(y,encoder_hidden_states=enc_hidden,encoder_attention_mask=cn_attn_mask)\n",
    "        # print('cn_en:{}{}'.format(output.shape,_.shape))\n",
    "        transformed=self.copy(output[:,-1:,:])\n",
    "        copy_scores=torch.bmm(enc_hidden,transformed.transpose(1,2)) \n",
    "        # copy_scores=torch.bmm(enc_hidden,transformed.unsqueeze(-1)) \n",
    "        gen_scores=self.linear(output[:,-1:,:])\n",
    "        # pred[:,_e]=self.linear(output)\n",
    "        # pred=self.linear(output)\n",
    "        # y=torch.tensor(pred[:,_e],dtype=torch.long,device=device).view(-1,1)  \n",
    "        y_pred=torch.tensor(torch.argmax(gen_scores,dim=-1),dtype=torch.long,device=device).view(-1,1)      \n",
    "        y=torch.cat((y,y_pred),dim=-1)\n",
    "        yield gen_scores,copy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjbTh3p9cqIm"
   },
   "outputs": [],
   "source": [
    "def token_to_string(id):\n",
    "  for d in dicts:\n",
    "    if(id in d):\n",
    "      return d[id]\n",
    "  return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jls3075hcsjY"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 50):\n",
    "        super(PositionalEncoder,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_seq_len, d_model,requires_grad=False,dtype=torch.float16).to(device)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        self.register_buffer('pe',pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(float(self.d_model))\n",
    "        #add positional embedding\n",
    "        seq_len = x.size(1)\n",
    "        # pe = torch.tensor(self.pe[:,:seq_len],requires_grad=False).to(device)\n",
    "        pe = self.pe[:,:seq_len,:].clone().detach()\n",
    "        return x + pe.expand_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDX2x1LhePkS"
   },
   "source": [
    "# Coverage loss can be used to impose a penalty for repeating tokens(not used as of now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl_MfSK6cu19"
   },
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k,mask=False,cover=None):\n",
    "  scores = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "  scores = F.softmax(scores, dim=-1) \n",
    "  if mask:\n",
    "    tensor_mask=torch.ones(scores.shape,dtype=torch.int8).to(device)\n",
    "    for row in range(tensor_mask.size(-2)):\n",
    "      for col in range(tensor_mask.size(-1)):\n",
    "        if(row>col):\n",
    "          tensor_mask[:,:,row,col]=0 \n",
    "    scores=scores * tensor_mask       \n",
    "    scores=scores.transpose(-2,-1)   \n",
    "  if(not cover is None):\n",
    "    tensor_mask=torch.ones([scores.size(0),scores.size(1),scores.size(-1),scores.size(-1)],\\\n",
    "                           dtype=torch.int8).to(device)\n",
    "    for row in range(tensor_mask.size(-2)):\n",
    "      for col in range(tensor_mask.size(-1)):\n",
    "        if(row>=col):\n",
    "          tensor_mask[:,:,row,col]=0 \n",
    "    tensor_mask=tensor_mask.transpose(-2,-1) \n",
    "    cv=torch.matmul(scores,tensor_mask)\n",
    "    cover+=torch.sum(torch.min(cv,scores),[0,1,2,3])     \n",
    "    # print(cover)     \n",
    "  output = torch.matmul(scores, v)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHmnziEocxOk"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,hidden_size,heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads=heads \n",
    "        self.d_k = hidden_size // heads\n",
    "        self.hidden_size=hidden_size\n",
    "        self.q_linear = nn.Linear(hidden_size, hidden_size,bias=False)\n",
    "        self.v_linear = nn.Linear(hidden_size, hidden_size,bias=False)\n",
    "        self.k_linear = nn.Linear(hidden_size, hidden_size,bias=False)        \n",
    "    \n",
    "    def forward(self, q, k, v,mask=False,cover=None):        \n",
    "        bs = q.size(0)\n",
    "        k = self.k_linear(k).view(bs,-1,self.heads,self.d_k)\n",
    "        q = self.q_linear(q).view(bs,-1,self.heads,self.d_k)\n",
    "        v = self.v_linear(v).view(bs,-1,self.heads,self.d_k)\n",
    "\n",
    "        k=k.transpose(1,2)\n",
    "        q=q.transpose(1,2)\n",
    "        v=v.transpose(1,2)\n",
    "\n",
    "        scores = attention(q, k, v, self.d_k,mask,cover)\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.hidden_size)\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLf33kMpczZ0"
   },
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "  def __init__(self,hidden_size):\n",
    "    super(Norm, self).__init__()\n",
    "    self.norm=nn.LayerNorm(hidden_size,elementwise_affine=False)\n",
    "  def forward(self,x,res):\n",
    "    x=x+self.norm(res)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJelViGCc00V"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self,hidden_size,d_ff=2048):\n",
    "    super(FeedForward, self).__init__()\n",
    "    self.linear_1=nn.Linear(hidden_size,d_ff)\n",
    "    self.linear_2=nn.Linear(d_ff,hidden_size)\n",
    "  def forward(self,x):\n",
    "    output=self.linear_1(x)\n",
    "    output=self.linear_2(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uAhN5cFeaKO"
   },
   "source": [
    "# Number of layers reduced to 6(memory considerations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AT5VWpEKc2b2"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,hidden_size,vocab_size):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.hidden_size=hidden_size\n",
    "    self.pos=PositionalEncoder(hidden_size)\n",
    "    self.embedding=nn.Embedding(vocab_size,hidden_size,padding_idx=0)\n",
    "    self.embedding.weight.requires_grad = False\n",
    "    self.attn1_layer_list=nn.ModuleList([])\n",
    "    self.attn2_layer_list=nn.ModuleList([])\n",
    "    self.norm_layer_list=nn.ModuleList([])\n",
    "    self.ff_layer_list=nn.ModuleList([])\n",
    "    for indx in range(6):\n",
    "      self.attn1_layer_list.append(MultiHeadAttention(hidden_size))    \n",
    "    for indx in range(6):\n",
    "      self.attn2_layer_list.append(MultiHeadAttention(hidden_size))\n",
    "    for indx in range(6):\n",
    "      self.norm_layer_list.append(Norm(hidden_size))\n",
    "    for indx in range(6):\n",
    "      self.ff_layer_list.append(FeedForward(hidden_size)) \n",
    "  def load_my_state_dict(self, state_dict):\n",
    "      own_state = self.state_dict()\n",
    "      for name, param in state_dict.items():          \n",
    "          if name !='embeddings.word_embeddings.weight':\n",
    "                continue                              \n",
    "          # own_state['embedding.weight'][:param.size(0),:].copy_(param)\n",
    "          own_state['embedding.weight'][:param.size(0),:]=param                 \n",
    "  def forward(self,seq,all_hidden_layer,coverage=None):\n",
    "    embedded=self.embedding(seq)\n",
    "    embedded=self.pos(embedded)\n",
    "\n",
    "    # output=self.attn_1(embedded,embedded,embedded,True)\n",
    "    for indx,layer in enumerate(all_hidden_layer):      \n",
    "      dec_hidden=self.attn1_layer_list[indx](embedded,embedded,embedded,True)\n",
    "      dec_hidden=self.norm_layer_list[indx](embedded,dec_hidden)\n",
    "      res=self.attn2_layer_list[indx](dec_hidden,layer,layer,cover=coverage)\n",
    "      output=self.norm_layer_list[indx](embedded,res)\n",
    "      res=self.ff_layer_list[indx](output)\n",
    "      dec_hidden=self.norm_layer_list[indx](output,res)\n",
    "      embedded=torch.clone(dec_hidden)\n",
    "    return dec_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXVfAhBze1az"
   },
   "source": [
    "# Training\n",
    "\n",
    "reduced number of layers but can be increased , if more memory is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "a55a15bc5e0f48fbb2f3bd161ae7cec7",
      "a69b73242d964b9ebd73c186a472e35d",
      "9b6bcae645aa42efb58a2516740690ef",
      "99428be3b1df4605b97649995ae2ef3d",
      "3b1460d3077c4f239f41c72cd422ecab",
      "c227f5f230af45a2b938c68df4b5de6d",
      "84f8fe4c40324040a490399d9d7e10af",
      "4134705103c34103af670932c164c6a7",
      "3d36ef1f88ee403b91491cbb18d3ca74",
      "729e2e1c2cf64a67be3389c9b497cbb7",
      "c264377d432d4e23870234905bd92757",
      "bb8bc3bd1b6e4ffaa274a17c00d17c95",
      "4210fa2318f643b79e189db572542817",
      "5220260a2ade457296dfb7110999e366",
      "8d9c1b5c815a412bbdefa66eaf3bfbed",
      "c2422774d89d4485bda548ea7b31501e",
      "ff5244fffc724aa7a9696ae7e72ad206",
      "a2cc37d9dd0142ccae503f5d45e63cd3",
      "0ee8cd41e905463aa759ba655cbce5d3",
      "0ee341a1a5eb46928d6c07d04a122605",
      "4733b0b2d40f4037bbd829a03a50b9db",
      "841f2ae9457544ecab04dbd18bcc74a7",
      "a1224999d9364ac99796f7239c8aed92",
      "0f37705e00624aadbbbf4bda803c9f2b",
      "cbb8ff649d5740c1b6efbbe924f0ee4a",
      "ef9c110d7b3244d982e145bf9fc150c7",
      "2ffb7a7ca0a0419e8fa05c0ea9446fde",
      "433a323857d94e0e884c8f9ee34a0c2d",
      "afac0ead34284f2eb15bfbd655763814",
      "5ad221d7e3f044df880ea496c61e9060",
      "ad8d12138a64496a9fec3bb053b4726b",
      "26483b00eea3416fa68389cbd846d3ee"
     ]
    },
    "colab_type": "code",
    "id": "OjUX_Epvc4r6",
    "outputId": "d02996ca-2115-4318-ca33-81bac84bf151"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55a15bc5e0f48fbb2f3bd161ae7cec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d36ef1f88ee403b91491cbb18d3ca74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5244fffc724aa7a9696ae7e72ad206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=695.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb8ff649d5740c1b6efbbe924f0ee4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411578458.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Iteration 0=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BERT_en_encoder=BertModel.from_pretrained('bert-base-uncased',\\\n",
    "                                        output_hidden_states=True,num_hidden_layers=5)\n",
    "BERT_cn_encoder=BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\",\\\n",
    "                                        output_hidden_states=True,num_hidden_layers=5)\n",
    "model_en_cn=Translator_EN_CN().to(device)\n",
    "model_en_cn.load_my_state_dict(torch.load('/content/drive/My Drive/translator_en_cn.pt'))\n",
    "model_cn_en=Translator_CN_EN().to(device)\n",
    "model_cn_en.load_my_state_dict(torch.load('/content/drive/My Drive/translator_cn_en.pt'))\n",
    "\n",
    "optimizer = optim.Adam(list(model_en_cn.parameters())+list(model_cn_en.parameters()) , lr = 1e-5)\n",
    "val_losses=[]\n",
    "en_id_str_dict={value:key for key,value in en_tokenizer.vocab.items()}\n",
    "cn_id_str_dict={value:key for key,value in cn_tokenizer.vocab.items()}\n",
    "for iter in range(100):\n",
    "  print('=============Iteration {}============='.format(iter))\n",
    "  train_loss=0\n",
    "  for i,batch in enumerate(train_loader):\n",
    "    loss=0\n",
    "    optimizer.zero_grad()\n",
    "    cn_encoding=torch.tensor(batch['x']).to(device)\n",
    "    cn_attn_mask=torch.tensor(batch['attn_mask']).to(device)\n",
    "    # print('original cn :',batch['src'])     \n",
    "    \n",
    "    # CN-EN translation          \n",
    "\n",
    "    vocab_en={}\n",
    "    indx=0\n",
    "    for tokens in batch['src']:\n",
    "      for token in tokens:\n",
    "        if(token in vocab_en or token in en_tokenizer.vocab):\n",
    "          continue\n",
    "        vocab_en.update({token:indx})\n",
    "        indx+=1 \n",
    "    vocab_en={key:value+len(en_tokenizer) for key,value in vocab_en.items()}\n",
    "    vocab_en_id_str={value:key for key,value in vocab_en.items()}  \n",
    "    \n",
    "    expanded_x_en=[]\n",
    "    copy_mask_en=[]\n",
    "    for tokens in batch['src']:\n",
    "      expanded_x_en.append([vocab_en[token]  if token in vocab_en\\\n",
    "                      else en_tokenizer.convert_tokens_to_ids(token) for token in tokens])      \n",
    "      copy_mask_en.append([1 if isEnglish(token) else 0 for token in tokens])   \n",
    "    expanded_x_en = [pad(item,en=True) for item in expanded_x_en]\n",
    "    copy_mask_en = [pad(item,en=False) for item in copy_mask_en]\n",
    "    expanded_x_en=torch.tensor(expanded_x_en,device=device)\n",
    "    copy_mask_en=torch.tensor(copy_mask_en,device=device)\n",
    "\n",
    "    pred=[]\n",
    "    for i,(gen_scores,copy_scores) in enumerate(model_cn_en(cn_encoding,cn_attn_mask)):\n",
    "      # expand gen scores to cover extra vocab\n",
    "      # print(gen_scores.shape,len(vocab_cn))\n",
    "      gen_scores=F.pad(gen_scores,(0,len(vocab_en)),'constant')             \n",
    "      gen_scores.squeeze(1).scatter_add_(1,expanded_x_en,copy_scores.squeeze(-1)\\\n",
    "                                          [:,:expanded_x_en.size(1)]*copy_mask_en)\n",
    "      # gen_scores.scatter_add_(1,expanded_x_en,copy_scores.view(1,-1)[:,:expanded_x_en.size(1)]*copy_mask_en)\n",
    "      pred.extend([torch.argmax(gen_scores,dim=-1).tolist()]) \n",
    "      # pred.extend([torch.argmax(gen_scores,dim=-1).tolist()])   \n",
    "    pred=[list(itm) for itm in zip(*pred)]    \n",
    "    dicts=[vocab_en_id_str,en_id_str_dict]   \n",
    "    # pred=list(map(list, zip(*pred)))    \n",
    "    pred=[list(map(token_to_string,[itm[0] for itm in batch])) for batch in pred]\n",
    "    \n",
    "    # print('english translation:',pred)\n",
    "\n",
    "    # create extra vocab\n",
    "    vocab={}\n",
    "    indx=len(cn_tokenizer) \n",
    "    for tokens in pred:\n",
    "      for token in tokens:\n",
    "        if(token in vocab):\n",
    "          continue\n",
    "        vocab.update({token:indx})\n",
    "        indx+=1          \n",
    "    vocab_id_str={value:key for key,value in vocab.items()} \n",
    "    expanded_x_cn=[]\n",
    "    for tokens in pred:\n",
    "      expanded_x_cn.append([vocab[token] for token in tokens])      \n",
    "\n",
    "    # expanded_x=[pad(item) for item in expanded_x]\n",
    "    expanded_x_cn=torch.tensor(expanded_x_cn,device=device)\n",
    "\n",
    "    # encode target with expanded vocab\n",
    "    target=[]\n",
    "    for tokens in batch['src']:\n",
    "      target.append([vocab[token] if token in vocab else \\\n",
    "                     cn_tokenizer.convert_tokens_to_ids(token) for token in tokens]\\\n",
    "                    +[cn_tokenizer.convert_tokens_to_ids('</s>')])\n",
    "    target=[pad(item,en=False) for item in target]\n",
    "    target=torch.tensor(target,device=device)    \n",
    "    # if(target.size(1)<100):\n",
    "    #   target=F.pad(target,(0,100-target.size(1)),'constant')\n",
    "\n",
    "    # EN-CN translation\n",
    "    # expanded_x=[]\n",
    "    en_encoding=[]\n",
    "    en_attn_mask=[]\n",
    "    # cn_mask=[]\n",
    "    for tokens in pred:\n",
    "      # cn_mask.append([1 if token in vocab else 0 for token in tokens])\n",
    "      # expanded_x.append([vocab[token] if token in vocab else cn_tokenizer.convert_tokens_to_ids(token)\\\n",
    "      #                    for token in tokens])     \n",
    "      en_encoding.append([en_tokenizer.convert_tokens_to_ids(token) for token in tokens])\n",
    "      en_attn_mask.append([1 if e!=en_tokenizer.convert_tokens_to_ids('[PAD]') else 0 for e in en_encoding[-1]])\n",
    "\n",
    "    # expanded_x=torch.tensor(expanded_x,device=device)\n",
    "    en_encoding=torch.tensor(en_encoding,device=device)\n",
    "    en_attn_mask=torch.tensor(en_attn_mask,device=device)\n",
    "    # en_mask=torch.tensor(en_mask,device=device)\n",
    "    pred=[]\n",
    "    # print(cn_encoding.shape,cn_attn_mask.shape)\n",
    "    for i,(gen_scores,copy_scores) in enumerate(model_en_cn(en_encoding,en_attn_mask,target)):\n",
    "      # expand gen scores to cover extra vocab\n",
    "      gen_scores=F.pad(gen_scores,(0,len(vocab)),'constant')      \n",
    "      gen_scores.squeeze(1).scatter_add_(1,expanded_x_cn,copy_scores.squeeze(-1)\\\n",
    "                                          [:,:expanded_x_cn.size(1)]) \n",
    "      # print(gen_scores[:,:,0])\n",
    "      # gen_scores.scatter_add_(1,expanded_x_cn,copy_scores.view(1,-1)[:,:expanded_x_cn.size(1)])     \n",
    "      loss+=F.cross_entropy(gen_scores.permute(0,2,1),target[:,i].view(-1,1),\\\n",
    "                            ignore_index=cn_tokenizer.convert_tokens_to_ids('[PAD]')) \n",
    "      # loss+=F.cross_entropy(gen_scores.unsqueeze(-1),target[:,i].view(-1,1),\\\n",
    "                            # ignore_index=cn_tokenizer.convert_tokens_to_ids('[PAD]'))                                      \n",
    "      pred.extend([torch.argmax(gen_scores,dim=-1).tolist()])      \n",
    "      # pred.extend([torch.argmax(gen_scores,dim=-1).tolist()])\n",
    "    pred=[list(itm) for itm in zip(*pred)]\n",
    "    dicts=[vocab_id_str,cn_id_str_dict]   \n",
    "    # pred=list(map(list, zip(*pred)))    \n",
    "    pred=[list(map(token_to_string,[itm[0] for itm in batch])) for batch in pred] \n",
    "    # print('chinese back:',pred)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    train_loss+=loss.data.item()\n",
    "  print('train loss:{}'.format(train_loss))\n",
    "\n",
    "  val_loss=0\n",
    "  with torch.no_grad():\n",
    "    for i,batch in enumerate(val_loader):\n",
    "      loss=0\n",
    "      optimizer.zero_grad()\n",
    "      cn_encoding=torch.tensor(batch['x']).to(device)\n",
    "      cn_attn_mask=torch.tensor(batch['attn_mask']).to(device)\n",
    "      # print('original cn :',batch['src'])     \n",
    "      \n",
    "      # CN-EN translation          \n",
    "\n",
    "      vocab_en={}\n",
    "      indx=0\n",
    "      for tokens in batch['src']:\n",
    "        for token in tokens:\n",
    "          if(token in vocab_en or token in en_tokenizer.vocab):\n",
    "            continue\n",
    "          vocab_en.update({token:indx})\n",
    "          indx+=1 \n",
    "      vocab_en={key:value+len(en_tokenizer) for key,value in vocab_en.items()}\n",
    "      vocab_en_id_str={value:key for key,value in vocab_en.items()}  \n",
    "      \n",
    "      expanded_x_en=[]\n",
    "      copy_mask_en=[]\n",
    "      for tokens in batch['src']:\n",
    "        expanded_x_en.append([vocab_en[token]  if token in vocab_en\\\n",
    "                        else en_tokenizer.convert_tokens_to_ids(token) for token in tokens])      \n",
    "        copy_mask_en.append([1 if isEnglish(token) else 0 for token in tokens])   \n",
    "      expanded_x_en = [pad(item,en=True) for item in expanded_x_en]\n",
    "      copy_mask_en = [pad(item,en=False) for item in copy_mask_en]      \n",
    "      expanded_x_en=torch.tensor(expanded_x_en,device=device)\n",
    "      copy_mask_en=torch.tensor(copy_mask_en,device=device)\n",
    "\n",
    "      pred=[]\n",
    "      for i,(gen_scores,copy_scores) in enumerate(model_cn_en(cn_encoding,cn_attn_mask)):\n",
    "        # expand gen scores to cover extra vocab\n",
    "        # print(gen_scores.shape,len(vocab_cn))\n",
    "        gen_scores=F.pad(gen_scores,(0,len(vocab_en)),'constant')           \n",
    "        gen_scores.squeeze(1).scatter_add_(1,expanded_x_en,copy_scores.squeeze(-1)\\\n",
    "                                            [:,:expanded_x_en.size(1)]*copy_mask_en)\n",
    "        # gen_scores.scatter_add_(1,expanded_x_en,copy_scores.view(1,-1)[:,:expanded_x_en.size(1)]*copy_mask_en)\n",
    "        pred.extend([torch.argmax(gen_scores,dim=-1).tolist()]) \n",
    "        # pred.extend([torch.argmax(gen_scores,dim=-1).tolist()])  \n",
    "      pred=[list(itm) for itm in zip(*pred)]  \n",
    "      dicts=[vocab_en_id_str,en_id_str_dict]   \n",
    "      # pred=list(map(list, zip(*pred)))    \n",
    "      pred=[list(map(token_to_string,[itm[0] for itm in batch])) for batch in pred]\n",
    "      \n",
    "      # print('english translation:',pred)\n",
    "\n",
    "      # create extra vocab\n",
    "      vocab={}\n",
    "      indx=len(cn_tokenizer) \n",
    "      for tokens in pred:\n",
    "        for token in tokens:\n",
    "          if(token in vocab):\n",
    "            continue\n",
    "          vocab.update({token:indx})\n",
    "          indx+=1          \n",
    "      vocab_id_str={value:key for key,value in vocab.items()} \n",
    "      expanded_x_cn=[]\n",
    "      for tokens in pred:\n",
    "        expanded_x_cn.append([vocab[token] for token in tokens])      \n",
    "\n",
    "      # expanded_x=[pad(item) for item in expanded_x]\n",
    "      expanded_x_cn=torch.tensor(expanded_x_cn,device=device)\n",
    "\n",
    "      # encode target with expanded vocab\n",
    "      target=[]\n",
    "      for tokens in batch['src']:\n",
    "        target.append([vocab[token] if token in vocab else \\\n",
    "                      cn_tokenizer.convert_tokens_to_ids(token) for token in tokens]\\\n",
    "                      +[cn_tokenizer.convert_tokens_to_ids('</s>')])\n",
    "      target=[pad(item,en=False) for item in target]\n",
    "      target=torch.tensor(target,dtype=torch.long,device=device)\n",
    "      # if(target.size(1)<100):\n",
    "      #   target=F.pad(target,(0,100-target.size(1)),'constant')\n",
    "\n",
    "      # EN-CN translation\n",
    "      # expanded_x=[]\n",
    "      en_encoding=[]\n",
    "      en_attn_mask=[]\n",
    "      # cn_mask=[]\n",
    "      for tokens in pred:\n",
    "        # cn_mask.append([1 if token in vocab else 0 for token in tokens])\n",
    "        # expanded_x.append([vocab[token] if token in vocab else cn_tokenizer.convert_tokens_to_ids(token)\\\n",
    "        #                    for token in tokens])     \n",
    "        en_encoding.append([en_tokenizer.convert_tokens_to_ids(token) for token in tokens])\n",
    "        en_attn_mask.append([1 if e!=en_tokenizer.convert_tokens_to_ids('[PAD]') else 0 for e in en_encoding[-1]])\n",
    "\n",
    "      # expanded_x=torch.tensor(expanded_x,device=device)\n",
    "      en_encoding=torch.tensor(en_encoding,device=device)\n",
    "      en_attn_mask=torch.tensor(en_attn_mask,device=device)\n",
    "      # en_mask=torch.tensor(en_mask,device=device)\n",
    "      pred=[]\n",
    "      # print(cn_encoding.shape,cn_attn_mask.shape)\n",
    "      for i,(gen_scores,copy_scores) in enumerate(model_en_cn(en_encoding,en_attn_mask,target)):\n",
    "        # expand gen scores to cover extra vocab\n",
    "        gen_scores=F.pad(gen_scores,(0,len(vocab)),'constant')      \n",
    "        gen_scores.squeeze(1).scatter_add_(1,expanded_x_cn,copy_scores.squeeze(-1)\\\n",
    "                                            [:,:expanded_x_cn.size(1)]) \n",
    "        # print(gen_scores[:,:,0])\n",
    "        # gen_scores.scatter_add_(1,expanded_x_cn,copy_scores.view(1,-1)[:,:expanded_x_cn.size(1)])     \n",
    "        loss+=F.cross_entropy(gen_scores.permute(0,2,1),target[:,i].view(-1,1),\\\n",
    "                              ignore_index=cn_tokenizer.convert_tokens_to_ids('[PAD]')) \n",
    "        # loss+=F.cross_entropy(gen_scores.unsqueeze(-1),target[:,i].view(-1,1),\\\n",
    "                              # ignore_index=cn_tokenizer.convert_tokens_to_ids('[PAD]'))                                      \n",
    "        pred.extend([torch.argmax(gen_scores,dim=-1).tolist()])      \n",
    "        # pred.extend([torch.argmax(gen_scores,dim=-1).tolist()])\n",
    "      pred=[list(itm) for itm in zip(*pred)] \n",
    "      dicts=[vocab_id_str,cn_id_str_dict]   \n",
    "      # pred=list(map(list, zip(*pred)))    \n",
    "      pred=[list(map(token_to_string,[itm[0] for itm in batch])) for batch in pred] \n",
    "      # print('chinese back:',pred)\n",
    "      val_loss+=loss.data.item()\n",
    "    print('validation loss:{}'.format(val_loss))\n",
    "    if(len(val_losses)>0 and val_loss<min(val_losses)):\n",
    "      torch.save(model_en_cn.state_dict(), '/content/drive/My Drive/translator_en_cn.pt')\n",
    "      torch.save(model_cn_en.state_dict(), '/content/drive/My Drive/translator_cn_en.pt')\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LGg6W8MdAOW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "translator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01bb59f213e2455cb6256bf178b3b3f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03084dc3b06f465ca353179a69aabab6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aaeee085ebd45bfa6291b523c26d901",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f43d78c1b4e94062adb2959c19fe0899",
      "value": 112
     }
    },
    "0474a13e1a2c454d997ea9c368f9f8cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_573c1b92dbfd4518826440c03290d70e",
      "placeholder": "​",
      "style": "IPY_MODEL_a31e3217a21d4ab0a641c2e97f49f795",
      "value": " 110k/110k [00:01&lt;00:00, 58.5kB/s]"
     }
    },
    "0d432b2a8a444774a633b01b4ca9de4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854d272bf39743d1986ab2fad2eced50",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed275708b57c4429ac285641ee9c2552",
      "value": 231508
     }
    },
    "0ee341a1a5eb46928d6c07d04a122605": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f37705e00624aadbbbf4bda803c9f2b",
      "placeholder": "​",
      "style": "IPY_MODEL_a1224999d9364ac99796f7239c8aed92",
      "value": " 695/695 [00:06&lt;00:00, 104B/s]"
     }
    },
    "0ee8cd41e905463aa759ba655cbce5d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_841f2ae9457544ecab04dbd18bcc74a7",
      "max": 695,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4733b0b2d40f4037bbd829a03a50b9db",
      "value": 695
     }
    },
    "0f37705e00624aadbbbf4bda803c9f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d3c2a86a1254f4cadb895e9b41e388c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7cb48430c834a90b30ec720737a0995",
      "max": 19,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e234cb4a063a4967b1cdd746fa4be3d9",
      "value": 19
     }
    },
    "2139e1f088fb498295fc8a8f5ed91504": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26483b00eea3416fa68389cbd846d3ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ffb7a7ca0a0419e8fa05c0ea9446fde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ad221d7e3f044df880ea496c61e9060",
      "max": 411578458,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afac0ead34284f2eb15bfbd655763814",
      "value": 411578458
     }
    },
    "36510477d3854a7faeb4a8b6290091f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2139e1f088fb498295fc8a8f5ed91504",
      "placeholder": "​",
      "style": "IPY_MODEL_6e73e180864c4d7aa69cc79ddbf46b9c",
      "value": " 2.00/2.00 [00:00&lt;00:00, 2.12B/s]"
     }
    },
    "36e3a5e0459a42c6ae56b904a3c5b8d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ab1015f09cc4d4580cd5a870b68a495": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b1460d3077c4f239f41c72cd422ecab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3d36ef1f88ee403b91491cbb18d3ca74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c264377d432d4e23870234905bd92757",
       "IPY_MODEL_bb8bc3bd1b6e4ffaa274a17c00d17c95"
      ],
      "layout": "IPY_MODEL_729e2e1c2cf64a67be3389c9b497cbb7"
     }
    },
    "4134705103c34103af670932c164c6a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4210fa2318f643b79e189db572542817": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "42ef4a3dc3144ca7a29ff9ce166232c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "433a323857d94e0e884c8f9ee34a0c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26483b00eea3416fa68389cbd846d3ee",
      "placeholder": "​",
      "style": "IPY_MODEL_ad8d12138a64496a9fec3bb053b4726b",
      "value": " 412M/412M [00:06&lt;00:00, 68.4MB/s]"
     }
    },
    "46f8f2e1fb1c4ceb80f683568410cf10": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4733b0b2d40f4037bbd829a03a50b9db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4752f00e5ea34933b21643fb0504bcb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47644331ac4746169a1055aef96dde93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d432b2a8a444774a633b01b4ca9de4d",
       "IPY_MODEL_f8854582c97a41bb827c7f251a9c14bc"
      ],
      "layout": "IPY_MODEL_3ab1015f09cc4d4580cd5a870b68a495"
     }
    },
    "5220260a2ade457296dfb7110999e366": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573c1b92dbfd4518826440c03290d70e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad221d7e3f044df880ea496c61e9060": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cc93970325e47419a7b82bcd7d0747c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76076bd868784a2780e983fa241b955c",
       "IPY_MODEL_36510477d3854a7faeb4a8b6290091f3"
      ],
      "layout": "IPY_MODEL_f6448e4550de464b850565bba205beed"
     }
    },
    "6e73e180864c4d7aa69cc79ddbf46b9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "729e2e1c2cf64a67be3389c9b497cbb7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76076bd868784a2780e983fa241b955c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9ed44d648794bb098c93cefa0fd226d",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6ad9a578195430dacfff55635cf9aa5",
      "value": 2
     }
    },
    "79453e6b7af14f7a86fa9c1be554c884": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "841f2ae9457544ecab04dbd18bcc74a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84329afb19a54968b62641dfad534c43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01bb59f213e2455cb6256bf178b3b3f2",
      "max": 109540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92c828dbb21c41ccaacb9d2bfbb65406",
      "value": 109540
     }
    },
    "84f8fe4c40324040a490399d9d7e10af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "854d272bf39743d1986ab2fad2eced50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aaeee085ebd45bfa6291b523c26d901": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d9c1b5c815a412bbdefa66eaf3bfbed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92c828dbb21c41ccaacb9d2bfbb65406": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "96a1db5631ea4637bfa97beeec4d9f84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99428be3b1df4605b97649995ae2ef3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4134705103c34103af670932c164c6a7",
      "placeholder": "​",
      "style": "IPY_MODEL_84f8fe4c40324040a490399d9d7e10af",
      "value": " 433/433 [00:06&lt;00:00, 64.1B/s]"
     }
    },
    "9b6bcae645aa42efb58a2516740690ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c227f5f230af45a2b938c68df4b5de6d",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b1460d3077c4f239f41c72cd422ecab",
      "value": 433
     }
    },
    "a1224999d9364ac99796f7239c8aed92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2cc37d9dd0142ccae503f5d45e63cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a31e3217a21d4ab0a641c2e97f49f795": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a55a15bc5e0f48fbb2f3bd161ae7cec7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b6bcae645aa42efb58a2516740690ef",
       "IPY_MODEL_99428be3b1df4605b97649995ae2ef3d"
      ],
      "layout": "IPY_MODEL_a69b73242d964b9ebd73c186a472e35d"
     }
    },
    "a69b73242d964b9ebd73c186a472e35d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a779e50ab1244f5db3fefd623542a8e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7cb48430c834a90b30ec720737a0995": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad8d12138a64496a9fec3bb053b4726b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afac0ead34284f2eb15bfbd655763814": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b9ed44d648794bb098c93cefa0fd226d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb8bc3bd1b6e4ffaa274a17c00d17c95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2422774d89d4485bda548ea7b31501e",
      "placeholder": "​",
      "style": "IPY_MODEL_8d9c1b5c815a412bbdefa66eaf3bfbed",
      "value": " 440M/440M [00:06&lt;00:00, 71.0MB/s]"
     }
    },
    "bd0a9e1bff99445da474823b5035fae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a779e50ab1244f5db3fefd623542a8e0",
      "placeholder": "​",
      "style": "IPY_MODEL_36e3a5e0459a42c6ae56b904a3c5b8d3",
      "value": " 19.0/19.0 [00:00&lt;00:00, 41.4B/s]"
     }
    },
    "bee1edf2183d4849a7c70e95061808eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c03f2b0ab812481f8770f4ea502fa2dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c227f5f230af45a2b938c68df4b5de6d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2422774d89d4485bda548ea7b31501e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c264377d432d4e23870234905bd92757": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5220260a2ade457296dfb7110999e366",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4210fa2318f643b79e189db572542817",
      "value": 440473133
     }
    },
    "cbb8ff649d5740c1b6efbbe924f0ee4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ffb7a7ca0a0419e8fa05c0ea9446fde",
       "IPY_MODEL_433a323857d94e0e884c8f9ee34a0c2d"
      ],
      "layout": "IPY_MODEL_ef9c110d7b3244d982e145bf9fc150c7"
     }
    },
    "d6ad9a578195430dacfff55635cf9aa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "de8dcb8b37014090882fccf4f1084577": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d3c2a86a1254f4cadb895e9b41e388c",
       "IPY_MODEL_bd0a9e1bff99445da474823b5035fae5"
      ],
      "layout": "IPY_MODEL_c03f2b0ab812481f8770f4ea502fa2dd"
     }
    },
    "e1aca9d720cc47cb8bcc5399218d4ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84329afb19a54968b62641dfad534c43",
       "IPY_MODEL_0474a13e1a2c454d997ea9c368f9f8cf"
      ],
      "layout": "IPY_MODEL_46f8f2e1fb1c4ceb80f683568410cf10"
     }
    },
    "e234cb4a063a4967b1cdd746fa4be3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ec8bb762f2a14ad89514ab85327aacda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03084dc3b06f465ca353179a69aabab6",
       "IPY_MODEL_f8ec86f5aaa3480f9edd0029a1640fc9"
      ],
      "layout": "IPY_MODEL_79453e6b7af14f7a86fa9c1be554c884"
     }
    },
    "ed275708b57c4429ac285641ee9c2552": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef9c110d7b3244d982e145bf9fc150c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f43d78c1b4e94062adb2959c19fe0899": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f6448e4550de464b850565bba205beed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8854582c97a41bb827c7f251a9c14bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bee1edf2183d4849a7c70e95061808eb",
      "placeholder": "​",
      "style": "IPY_MODEL_96a1db5631ea4637bfa97beeec4d9f84",
      "value": " 232k/232k [00:00&lt;00:00, 726kB/s]"
     }
    },
    "f8ec86f5aaa3480f9edd0029a1640fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42ef4a3dc3144ca7a29ff9ce166232c1",
      "placeholder": "​",
      "style": "IPY_MODEL_4752f00e5ea34933b21643fb0504bcb8",
      "value": " 112/112 [00:01&lt;00:00, 91.2B/s]"
     }
    },
    "ff5244fffc724aa7a9696ae7e72ad206": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ee8cd41e905463aa759ba655cbce5d3",
       "IPY_MODEL_0ee341a1a5eb46928d6c07d04a122605"
      ],
      "layout": "IPY_MODEL_a2cc37d9dd0142ccae503f5d45e63cd3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
